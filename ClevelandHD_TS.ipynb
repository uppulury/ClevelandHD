{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnlist = ['C0','C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13']\n",
    "k=1 #to adjust the row indices\n",
    "ClevelandHD = pd.read_csv(\"processed.cleveland.data\",delimiter=\",\",names=columnlist)\n",
    "ClevelandHDMat = ClevelandHD.values\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess Data\n",
    "\n",
    "A11arr = np.where(ClevelandHDMat[:,11]=='?')\n",
    "A12arr = np.where(ClevelandHDMat[:,12]=='?')\n",
    "\n",
    "A11 = np.delete(ClevelandHDMat[:,11],A11arr)\n",
    "A12 = np.delete(ClevelandHDMat[:,12],A12arr)\n",
    "A11 = np.mean(A11.astype(np.float))\n",
    "A12 = np.mean(A12.astype(np.float))\n",
    "\n",
    "#Assign Random values to the missing records in \"C11\" (\"Major Vessels Colored\")\n",
    "A11 = np.array(np.random.randint(0,4,4),dtype=float)\n",
    "ClevelandHD.iloc[165+k,11] = str(A11[0])\n",
    "ClevelandHD.iloc[191+k,11] = str(A11[1])\n",
    "ClevelandHD.iloc[286+k,11] = str(A11[2])\n",
    "ClevelandHD.iloc[301+k,11] = str(A11[3])\n",
    "\n",
    "#Assign missing values in 'C12' randomly to '3' and '6'\n",
    "A12 = [3.0,6.0]\n",
    "ClevelandHD.iloc[86+k,12] = str(A12[0])\n",
    "ClevelandHD.iloc[265+k,12] = str(A12[1])\n",
    "\n",
    "ClevelandHDMat = ClevelandHD.values\n",
    "ClevelandHDMat = ClevelandHDMat.astype(float)\n",
    "\n",
    "#Classify groups-(1,2,3,4) into one group\n",
    "for i in range(0,len(ClevelandHD)):\n",
    "    if ClevelandHD.values[i,13]>=2:\n",
    "        ClevelandHDMat[i,13]=1\n",
    "        ClevelandHD.iloc[i,13]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Distribution of Disease Diagnosis')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "\n",
    "# print type(ClevelandHD.iloc[1,1])\n",
    "\n",
    "ax = ClevelandHD.iloc[0:302,13].plot.hist(color='red')\n",
    "ax.set_xlabel('Disease Diagnosis',size=20,fontweight='bold')\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "ax.set_ylabel('Counts',size=20,fontweight='bold')\n",
    "ax.set_title('Distribution of Disease Diagnosis',fontsize=20,fontweight='bold')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           C0        C1        C2        C3        C4        C5        C6  \\\n",
      "C0   1.000000 -0.097542  0.104139  0.284946  0.208950  0.118530  0.148868   \n",
      "C1  -0.097542  1.000000  0.010084 -0.064456 -0.199915  0.047862  0.021647   \n",
      "C2   0.104139  0.010084  1.000000 -0.036077  0.072319 -0.039975  0.067505   \n",
      "C3   0.284946 -0.064456 -0.036077  1.000000  0.130120  0.175340  0.146560   \n",
      "C4   0.208950 -0.199915  0.072319  0.130120  1.000000  0.009841  0.171043   \n",
      "C5   0.118530  0.047862 -0.039975  0.175340  0.009841  1.000000  0.069564   \n",
      "C6   0.148868  0.021647  0.067505  0.146560  0.171043  0.069564  1.000000   \n",
      "C7  -0.393806 -0.048663 -0.334422 -0.045351 -0.003432 -0.007854 -0.083389   \n",
      "C8   0.091661  0.146201  0.384060  0.064762  0.061310  0.025665  0.084867   \n",
      "C9   0.203805  0.102173  0.202277  0.189171  0.046564  0.005747  0.114133   \n",
      "C10  0.161770  0.037533  0.152050  0.117382 -0.004062  0.059894  0.133946   \n",
      "C13  0.223120  0.276816  0.414446  0.150825  0.085164  0.025264  0.169202   \n",
      "\n",
      "           C7        C8        C9       C10       C13  \n",
      "C0  -0.393806  0.091661  0.203805  0.161770  0.223120  \n",
      "C1  -0.048663  0.146201  0.102173  0.037533  0.276816  \n",
      "C2  -0.334422  0.384060  0.202277  0.152050  0.414446  \n",
      "C3  -0.045351  0.064762  0.189171  0.117382  0.150825  \n",
      "C4  -0.003432  0.061310  0.046564 -0.004062  0.085164  \n",
      "C5  -0.007854  0.025665  0.005747  0.059894  0.025264  \n",
      "C6  -0.083389  0.084867  0.114133  0.133946  0.169202  \n",
      "C7   1.000000 -0.378103 -0.343085 -0.385601 -0.417167  \n",
      "C8  -0.378103  1.000000  0.288223  0.257748  0.431894  \n",
      "C9  -0.343085  0.288223  1.000000  0.577537  0.424510  \n",
      "C10 -0.385601  0.257748  0.577537  1.000000  0.339213  \n",
      "C13 -0.417167  0.431894  0.424510  0.339213  1.000000  \n"
     ]
    }
   ],
   "source": [
    "#Plotting\n",
    "%matplotlib tk\n",
    "\n",
    "# for i in range(0,14):\n",
    "#     print type(ClevelandHDMat[4,i])\n",
    "    \n",
    "# Plot the Histogram\n",
    "fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "ClevelandHD.hist(sharex=False,sharey=False,xlabelsize=1,ylabelsize=1)\n",
    "plt.show()\n",
    "\n",
    "# Plot the Density_Plot\n",
    "fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "ClevelandHD.plot(kind='Density',subplots=True,layout=(4,4))\n",
    "plt.show()\n",
    "\n",
    "# Plot the Heat_Map\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(ClevelandHD.corr(),vmin=-1,vmax=1,interpolation='none')\n",
    "fig.colorbar(cax)\n",
    "plt.show()\n",
    "\n",
    "print ClevelandHD.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 61 303 303\n"
     ]
    }
   ],
   "source": [
    "#Define Train and Validation Sets\n",
    "\n",
    "X = ClevelandHDMat[:,0:12]\n",
    "y = ClevelandHDMat[:,13]\n",
    "\n",
    "validation_size = 0.2\n",
    "seed = 3\n",
    "X_train, X_validationset, y_train, y_validationset = train_test_split(X,y,test_size=validation_size,random_state=seed)\n",
    "\n",
    "print len(X_train), len(X_validationset),len(X_train)+len(X_validationset),len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LR: 0.801333 0.114508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnaveni/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA: 0.797167 0.099792\n",
      "CART: 0.772833 0.058860\n",
      "SVM: 0.537167 0.121053\n",
      "KNN: 0.620333 0.097487\n",
      "NB: 0.813667 0.088440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnaveni/anaconda2/lib/python2.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Define Models\n",
    "\n",
    "models = []\n",
    "results = []\n",
    "\n",
    "models.append(['LR',LogisticRegression()])\n",
    "models.append(['LDA',LinearDiscriminantAnalysis()])\n",
    "models.append(['CART',DecisionTreeClassifier()])\n",
    "models.append(['SVM',SVC()])\n",
    "models.append(['KNN',KNeighborsClassifier()])\n",
    "models.append(['NB',GaussianNB()])\n",
    "\n",
    "#Define Metrics\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "num_folds = 10\n",
    "print \"\"\n",
    "\n",
    "#Evaluate Models\n",
    "for name,model in models:\n",
    "    kfold = KFold(n_splits=num_folds,random_state=seed)\n",
    "    cv_results = cross_val_score(model,X_train,y_train,cv=kfold,scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f %f\" % (name,cv_results.mean(),cv_results.std())\n",
    "    print msg\n",
    "\n",
    "print \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the different Algorithm Responses\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Comparison of Algorithms\",fontsize=20,fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('Algorithm',size=20,fontweight='bold')\n",
    "plt.ylabel('Accuracy',size=20,fontweight='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledLR: 0.801500 0.106650 13.306252\n",
      "ScaledLDA: 0.797167 0.099792 12.518284\n",
      "ScaledCART: 0.760333 0.054873 7.216911\n",
      "ScaledKNN: 0.772167 0.078334 10.144638\n",
      "ScaledNB: 0.813667 0.088440 10.869262\n",
      "ScaledSVM: 0.817833 0.077485 9.474418\n"
     ]
    }
   ],
   "source": [
    "#Standardize the Models\n",
    "\n",
    "models_standardized = []\n",
    "models_standardized.append(('ScaledLR',Pipeline([('Scaler',StandardScaler()),('LR',LogisticRegression())])))\n",
    "models_standardized.append(('ScaledLDA',Pipeline([('Scaler',StandardScaler()),('LDA',LinearDiscriminantAnalysis())])))\n",
    "models_standardized.append(('ScaledCART',Pipeline([('Scaler',StandardScaler()),('CART',DecisionTreeClassifier())])))\n",
    "models_standardized.append(('ScaledKNN',Pipeline([('Scaler',StandardScaler()),('KNN',KNeighborsClassifier())])))\n",
    "models_standardized.append(('ScaledNB',Pipeline([('Scaler',StandardScaler()),('NB',GaussianNB())])))\n",
    "models_standardized.append(('ScaledSVM',Pipeline([('Scaler',StandardScaler()),('SVM',SVC())])))\n",
    "\n",
    "results_standardized = []\n",
    "names = []\n",
    "\n",
    "for name,model in models_standardized:\n",
    "    kfold = KFold(n_splits=num_folds,random_state=seed)\n",
    "    cv_results = cross_val_score(model,X_train,y_train,cv=kfold,scoring=scoring)\n",
    "    results_standardized.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f %f %f\" % (name, cv_results.mean(), cv_results.std(), cv_results.std()*100/cv_results.mean())\n",
    "    print msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Responses from Standardization\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Comparison of Algorithms\",fontsize=20,fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results_standardized)\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('Algorithm',size=20,fontweight='bold')\n",
    "plt.ylabel('Accuracy',size=20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best score is 0.801653 and the best parameters are {'C': 1}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnaveni/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/krishnaveni/anaconda2/lib/python2.7/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#Tuning the Algorithms\n",
    "\n",
    "#1, Tune The Scaled LR Model\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "kfold = KFold(n_splits=num_folds,random_state=seed)\n",
    "c_values = [1,3,5,7,9,11,13,15,17,19,21]\n",
    "param_grid = dict(C = c_values)\n",
    "model = LogisticRegression()\n",
    "grid = GridSearchCV(estimator=model,cv=kfold,scoring=scoring,param_grid=param_grid)\n",
    "grid_result = grid.fit(rescaledX,y_train)\n",
    "print \"\"\n",
    "print \"Best score is %f and the best parameters are %s\" % (grid_result.best_score_,grid_result.best_params_)\n",
    "print \"\"\n",
    "\n",
    "mean_grid = grid_result.cv_results_['mean_test_score']\n",
    "std_grid = grid_result.cv_results_['std_test_score']\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.suptitle(\"Tuned Scaled Logistic Regression Model\",fontsize=20,fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.scatter(c_values,mean_grid)\n",
    "plt.errorbar(c_values,mean_grid,std_grid)\n",
    "ax.set_xticklabels(c_values)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('C_values',size=20,fontweight='bold')\n",
    "plt.ylabel('Accuracy',size=20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best score is 0.805785 and the best parameters are {'n_neighbors': 21}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnaveni/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Tuning the Algorithm\n",
    "\n",
    "#2 Tune the KNN Model\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "kfold = KFold(n_splits=num_folds,random_state=seed)\n",
    "neighbors = [1,3,5,7,9,11,13,15,17,19,21]\n",
    "param_grid = dict(n_neighbors=neighbors)\n",
    "model = KNeighborsClassifier()\n",
    "grid = GridSearchCV(estimator=model,cv=kfold,scoring=scoring,param_grid=param_grid)\n",
    "grid_result = grid.fit(rescaledX,y_train)\n",
    "print \"\"\n",
    "print \"Best score is %f and the best parameters are %s\" % (grid_result.best_score_,grid_result.best_params_)\n",
    "print \"\"\n",
    "\n",
    "mean_grid = grid_result.cv_results_['mean_test_score']\n",
    "std_grid = grid_result.cv_results_['std_test_score']\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.suptitle(\"Tuned Scaled Logistic Regression Model\",fontsize=20,fontweight='bold')\n",
    "plt.scatter(neighbors,mean_grid)\n",
    "plt.errorbar(neighbors,mean_grid,std_grid)\n",
    "\n",
    "ax.set_xticklabels(neighbors)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('k_neighbors',size=20,fontweight='bold')\n",
    "plt.ylabel('Accuracy',size=20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB: 0.777167 (0.099488)\n",
      "GBM: 0.796833 (0.106910)\n",
      "RF: 0.780833 (0.074823)\n",
      "ET: 0.801000 (0.070132)\n"
     ]
    }
   ],
   "source": [
    "# TRY ENSEMBLE METHODS (K-FOLD CV)\n",
    "ensembles = []\n",
    "ensembles.append(('AB',AdaBoostClassifier()))\n",
    "ensembles.append(('GBM',GradientBoostingClassifier()))\n",
    "ensembles.append(('RF',RandomForestClassifier()))\n",
    "ensembles.append(('ET',ExtraTreesClassifier()))\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    \n",
    "#Compare the different ENSEMBLE Algorithm Responses\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.suptitle(\"Comparison of Ensemble Algorithms (10-Fold CV)\",fontsize=20,fontweight='bold')\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('Algorithms',size=20,fontweight='bold')\n",
    "plt.ylabel('Accuracy',size=20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB 0.8032786885245902\n",
      "GBM 0.7704918032786885\n",
      "RF 0.7213114754098361\n",
      "ET 0.8032786885245902\n",
      "\n",
      "\n",
      "['AB', 'GBM', 'RF', 'ET']\n",
      "[0.8032786885245902, 0.7704918032786885, 0.7213114754098361, 0.8032786885245902]\n"
     ]
    }
   ],
   "source": [
    "#1.TRY Fit-Predict using Boosting Algorithms on the Train-Validation Sets\n",
    "\n",
    "# model = LogisticRegression()\n",
    "models = []\n",
    "models.append(['AB',AdaBoostClassifier()])\n",
    "models.append(['GBM',GradientBoostingClassifier()])\n",
    "models.append(['RF',RandomForestClassifier()])\n",
    "models.append(['ET',ExtraTreesClassifier()])\n",
    "\n",
    "names = []\n",
    "results = []\n",
    "\n",
    "for name,model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    result = model.predict(X_validationset)\n",
    "    print name, accuracy_score(y_validationset,result)\n",
    "    names.append(name)\n",
    "    results.append(accuracy_score(y_validationset,result))\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.suptitle(\"Predict-Score Ensemble Algorithms\",fontsize=20,fontweight='bold')\n",
    "ax.scatter(names,results,color='blue')\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('Algorithms',size=20,fontweight='bold')\n",
    "plt.ylabel('Accuracy',size=20,fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "print \"\"\n",
    "print \"\"\n",
    "print names\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB 0.8032786885245902\n",
      "GBM 0.7704918032786885\n",
      "RF 0.7704918032786885\n",
      "ET 0.8032786885245902\n"
     ]
    }
   ],
   "source": [
    "#2.TRY Fit-Predict using Boosting Algorithms on the Scaled Train-Validation Sets\n",
    "\n",
    "models = []\n",
    "models.append(['AB',AdaBoostClassifier()])\n",
    "models.append(['GBM',GradientBoostingClassifier()])\n",
    "models.append(['RF',RandomForestClassifier()])\n",
    "models.append(['ET',ExtraTreesClassifier()])\n",
    "\n",
    "names = []\n",
    "results = []\n",
    "\n",
    "for name,model in models:\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    rescaledX = scaler.transform(X_train)\n",
    "    model.fit(rescaledX,y_train)\n",
    "    rescaled_ValidationX = scaler.transform(X_validationset)\n",
    "    result = model.predict(rescaled_ValidationX)\n",
    "    print name, accuracy_score(y_validationset,result)\n",
    "    names.append(name)\n",
    "    results.append(accuracy_score(y_validationset,result))\n",
    "    \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.suptitle(\"Predict-Score Scaled Ensemble Algorithms\",fontsize=20,fontweight='bold')\n",
    "ax.scatter(names,results,color='blue')\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('Algorithms',size=20,fontweight='bold')\n",
    "plt.ylabel('Accuracy',size=20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnaveni/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182 {'kernel': 'sigmoid', 'C': 0.1}\n",
      "[0.80165289 0.73553719 0.81404959 0.81818182 0.7892562  0.74380165\n",
      " 0.80991736 0.79752066 0.78512397 0.75619835 0.80991736 0.80165289\n",
      " 0.78099174 0.77272727 0.80991736 0.80991736 0.7892562  0.79338843\n",
      " 0.81404959 0.80578512 0.78099174 0.7768595  0.81818182 0.80578512\n",
      " 0.78099174 0.78099174 0.80991736 0.7892562  0.78512397 0.7892562\n",
      " 0.80165289 0.80165289 0.78099174 0.79338843 0.7892562  0.78512397\n",
      " 0.78099174 0.7892562  0.78512397 0.78512397 0.78099174 0.79338843\n",
      " 0.7892562  0.7768595  0.78099174 0.79338843 0.79338843 0.79752066\n",
      " 0.78099174 0.79338843 0.79338843 0.79338843 0.78512397 0.7892562\n",
      " 0.79338843 0.78512397 0.78512397 0.78512397 0.79338843 0.76446281\n",
      " 0.78512397 0.78512397 0.79752066 0.77272727 0.78512397 0.78099174\n",
      " 0.79752066 0.77272727 0.78512397 0.7768595  0.80165289 0.75619835\n",
      " 0.78512397 0.7768595  0.80165289 0.77272727 0.78512397 0.76446281\n",
      " 0.80991736 0.78512397 0.78512397 0.76859504 0.80991736 0.76859504\n",
      " 0.78512397 0.76446281 0.80165289 0.77272727 0.78512397 0.76446281\n",
      " 0.79752066 0.76859504 0.78512397 0.76033058 0.79752066 0.76859504\n",
      " 0.78512397 0.76033058 0.79752066 0.78512397]\n",
      "SVM c= 0.1 : 0.819672131147541\n",
      "SVM c= 0.2 : 0.8032786885245902\n",
      "SVM c= 0.30000000000000004 : 0.8032786885245902\n",
      "SVM c= 0.4 : 0.7868852459016393\n",
      "SVM c= 0.5 : 0.7868852459016393\n",
      "SVM c= 0.6 : 0.7868852459016393\n",
      "SVM c= 0.7000000000000001 : 0.7868852459016393\n",
      "SVM c= 0.8 : 0.8032786885245902\n",
      "SVM c= 0.9 : 0.7868852459016393\n",
      "SVM c= 1.0 : 0.8032786885245902\n",
      "SVM c= 1.1 : 0.819672131147541\n",
      "SVM c= 1.2000000000000002 : 0.819672131147541\n",
      "SVM c= 1.3000000000000003 : 0.819672131147541\n",
      "SVM c= 1.4000000000000001 : 0.819672131147541\n",
      "SVM c= 1.5000000000000002 : 0.819672131147541\n",
      "SVM c= 1.6 : 0.8032786885245902\n",
      "SVM c= 1.7000000000000002 : 0.8032786885245902\n",
      "SVM c= 1.8000000000000003 : 0.8032786885245902\n",
      "SVM c= 1.9000000000000001 : 0.8032786885245902\n",
      "SVM c= 2.0 : 0.8032786885245902\n",
      "SVM c= 2.1 : 0.8032786885245902\n",
      "SVM c= 2.2 : 0.8032786885245902\n",
      "SVM c= 2.3000000000000003 : 0.8032786885245902\n",
      "SVM c= 2.4000000000000004 : 0.8032786885245902\n",
      "SVM c= 2.5000000000000004 : 0.8032786885245902\n",
      "SVM c= 2.6 : 0.8032786885245902\n",
      "SVM c= 2.7 : 0.8032786885245902\n",
      "SVM c= 2.8000000000000003 : 0.8032786885245902\n",
      "SVM c= 2.9000000000000004 : 0.8032786885245902\n",
      "SVM c= 3.0000000000000004 : 0.7868852459016393\n",
      "SVM c= 3.1 : 0.7868852459016393\n",
      "SVM c= 3.2 : 0.8032786885245902\n",
      "SVM c= 3.3000000000000003 : 0.8032786885245902\n",
      "SVM c= 3.4000000000000004 : 0.8032786885245902\n",
      "SVM c= 3.5000000000000004 : 0.8032786885245902\n",
      "SVM c= 3.6 : 0.8032786885245902\n",
      "SVM c= 3.7 : 0.8032786885245902\n",
      "SVM c= 3.8000000000000003 : 0.8032786885245902\n",
      "SVM c= 3.9000000000000004 : 0.8032786885245902\n",
      "SVM c= 4.0 : 0.8032786885245902\n",
      "SVM c= 4.1 : 0.8032786885245902\n",
      "SVM c= 4.2 : 0.8032786885245902\n",
      "SVM c= 4.3 : 0.8032786885245902\n",
      "SVM c= 4.3999999999999995 : 0.8032786885245902\n",
      "SVM c= 4.5 : 0.8032786885245902\n",
      "SVM c= 4.6 : 0.8032786885245902\n",
      "SVM c= 4.7 : 0.8032786885245902\n",
      "SVM c= 4.8 : 0.8032786885245902\n",
      "SVM c= 4.9 : 0.7868852459016393\n",
      "SVM c= 5.0 : 0.7868852459016393\n"
     ]
    }
   ],
   "source": [
    "#Tune the Scaled-SVM Model\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "c_values = [0.1,0.3,0.5,0.7,0.9,1.1,1.3,1.5,1.7,1.9,2.1,2.3,2.5,2.7,2.9,3.1,3.3,3.5,3.7,4.1,4.3,4.5,4.7,4.9,5.1]\n",
    "kernel_values = ['linear','poly','rbf','sigmoid']\n",
    "param_grid = dict(C=c_values,kernel=kernel_values)\n",
    "model = SVC()\n",
    "kfold = KFold(n_splits=num_folds,random_state=seed)\n",
    "grid = GridSearchCV(estimator=model,scoring=scoring,cv=kfold,param_grid=param_grid)\n",
    "grid_result = grid.fit(rescaledX,y_train)\n",
    "print grid_result.best_score_, grid_result.best_params_\n",
    "\n",
    "mean_test_score = grid_result.cv_results_['mean_test_score']\n",
    "std_test_score = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "# print mean_test_score\n",
    "\n",
    "c_values = np.arange(0.1,5.1,0.1)\n",
    "name = 'SVM'\n",
    "for c in c_values:\n",
    "    model = SVC(C=c)\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    rescaledX = scaler.transform(X_train)\n",
    "    model.fit(rescaledX,y_train)\n",
    "    rescaled_ValidationX = scaler.transform(X_validationset)\n",
    "    result = model.predict(rescaled_ValidationX)\n",
    "    print name,\"c=\",c,\":\", accuracy_score(y_validationset,result)\n",
    "\n",
    "    \n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111)\n",
    "# fig.suptitle(\"Tuned Scaled Logistic Regression Model\",fontsize=20,fontweight='bold')\n",
    "# plt.scatter(neighbors,mean_grid)\n",
    "# plt.errorbar(neighbors,mean_grid,std_grid)\n",
    "\n",
    "# ax.set_xticklabels(neighbors)\n",
    "# ax.tick_params(axis='both',labelsize=15)\n",
    "# # ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# # ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "# plt.xlabel('k_neighbors',size=20,fontweight='bold')\n",
    "# plt.ylabel('Accuracy',size=20,fontweight='bold')\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVC (C=0.1,kernel = 'sigmoid') is:  0.8032786885245902\n",
      "\n",
      "The Confusion-Matrix is:  [[28  6]\n",
      " [ 6 21]]\n",
      "\n",
      "The Classification-Report is:                precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82        34\n",
      "         1.0       0.78      0.78      0.78        27\n",
      "\n",
      "   micro avg       0.80      0.80      0.80        61\n",
      "   macro avg       0.80      0.80      0.80        61\n",
      "weighted avg       0.80      0.80      0.80        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#FINALIZE the Model\n",
    "\n",
    "model = SVC(C=0.1,kernel='sigmoid')\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "model.fit(rescaledX,y_train)\n",
    "rescaled_ValidationX = scaler.transform(X_validationset)\n",
    "result = model.predict(rescaled_ValidationX)\n",
    "print \"Accuracy of SVC (C=0.1,kernel = 'sigmoid') is: \", accuracy_score(y_validationset,result)\n",
    "print \"\"\n",
    "print \"The Confusion-Matrix is: \", confusion_matrix(y_validationset,result)\n",
    "print \"\"\n",
    "print \"The Classification-Report is: \", classification_report(y_validationset,result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
